{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Representaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# %pip install seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'Review': [\n",
    "        \"I love this product\",\n",
    "        \"This worst is the worst purchase I've made\",\n",
    "        \"Absolutely fantastic  quality!\",\n",
    "        \"Terrible experience, not recommended\",\n",
    "        \"I'm very happy very with this\",\n",
    "        \"Do not buy this, it's bad\",\n",
    "        \"Excellent value for the money\",\n",
    "        \"Worst product ever\",\n",
    "        \"Very satisfied with the service\",\n",
    "        \"I hate this hate so much\"\n",
    "    ],\n",
    "    'Sentiment': [\n",
    "        \"positive\",\n",
    "        \"negative\",\n",
    "        \"positive\",\n",
    "        \"negative\",\n",
    "        \"positive\",\n",
    "        \"negative\",\n",
    "        \"positive\",\n",
    "        \"negative\",\n",
    "        \"positive\",\n",
    "        \"negative\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This worst is the worst purchase I've made</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Absolutely fantastic  quality!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Terrible experience, not recommended</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm very happy very with this</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Review Sentiment\n",
       "0                         I love this product  positive\n",
       "1  This worst is the worst purchase I've made  negative\n",
       "2              Absolutely fantastic  quality!  positive\n",
       "3        Terrible experience, not recommended  negative\n",
       "4               I'm very happy very with this  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nltk\n",
    "# %pip install scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()\n",
    "bow=cv.fit_transform(df['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love': 13, 'this': 27, 'product': 18, 'worst': 32, 'is': 11, 'the': 26, 'purchase': 19, 've': 29, 'made': 14, 'absolutely': 0, 'fantastic': 7, 'quality': 20, 'terrible': 25, 'experience': 6, 'not': 17, 'recommended': 21, 'very': 30, 'happy': 9, 'with': 31, 'do': 3, 'buy': 2, 'it': 12, 'bad': 1, 'excellent': 5, 'value': 28, 'for': 8, 'money': 15, 'ever': 4, 'satisfied': 22, 'service': 23, 'hate': 10, 'so': 24, 'much': 16}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 2]]\n",
      "[[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 1 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 2]]\n",
      "[[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 1 0]]\n",
      "[[0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]]\n",
      "[[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())\n",
    "print(bow[1].toarray())\n",
    "print(bow[2].toarray())\n",
    "print(bow[3].toarray())\n",
    "print(bow[4].toarray())\n",
    "for i in range(len(bow.toarray())):\n",
    "    print(bow[i].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 2]]\n",
      "[[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 1 0]]\n",
      "[[0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]]\n",
      "[[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Bag of Words (BoW) is a simple and commonly used method for text representation in Natural Language Processing (NLP). It converts text documents into numerical feature vectors, which can then be used for various machine learning tasks. The basic idea is to represent each document as a vector of word counts or binary values, indicating the presence or absence of words in the document\n",
    "for i in range(len(bow.toarray())):\n",
    "    print(bow[i].toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love this product': 10, 'this worst is': 18, 'worst is the': 24, 'is the worst': 9, 'the worst purchase': 15, 'worst purchase ve': 26, 'purchase ve made': 12, 'absolutely fantastic quality': 0, 'terrible experience not': 14, 'experience not recommended': 4, 'very happy very': 20, 'happy very with': 6, 'very with this': 22, 'do not buy': 2, 'not buy this': 11, 'buy this it': 1, 'this it bad': 17, 'excellent value for': 3, 'value for the': 19, 'for the money': 5, 'worst product ever': 25, 'very satisfied with': 21, 'satisfied with the': 13, 'with the service': 23, 'hate this hate': 8, 'this hate so': 16, 'hate so much': 7}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(3,3))\n",
    "bow = cv.fit_transform(df['Review'])\n",
    "print(cv.vocabulary_)\n",
    "print(len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People wathch anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anime watch anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People wite comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anime write anime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text\n",
       "0  People wathch anime\n",
       "1    anime watch anime\n",
       "2  People wite comment\n",
       "3    anime write anime"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample documents\n",
    "docs = [\n",
    "    \"People wathch anime\",\n",
    "    \"anime watch anime\",\n",
    "    \"People wite comment\",\n",
    "    \"anime write anime\"\n",
    "]\n",
    "doc=pd.DataFrame(docs, columns=['text'])\n",
    "\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44809973 0.         0.55349232 0.         0.70203482 0.\n",
      "  0.        ]\n",
      " [0.78722298 0.         0.         0.61666846 0.         0.\n",
      "  0.        ]\n",
      " [0.         0.61761437 0.48693426 0.         0.         0.61761437\n",
      "  0.        ]\n",
      " [0.78722298 0.         0.         0.         0.         0.\n",
      "  0.61666846]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tf_idf = tfidf.fit_transform(doc['text'])\n",
    "print(tf_idf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      anime   comment    people     watch    wathch      wite     write\n",
      "0  0.448100  0.000000  0.553492  0.000000  0.702035  0.000000  0.000000\n",
      "1  0.787223  0.000000  0.000000  0.616668  0.000000  0.000000  0.000000\n",
      "2  0.000000  0.617614  0.486934  0.000000  0.000000  0.617614  0.000000\n",
      "3  0.787223  0.000000  0.000000  0.000000  0.000000  0.000000  0.616668\n"
     ]
    }
   ],
   "source": [
    "x=pd.DataFrame(tf_idf.toarray(), columns=tfidf.get_feature_names_out())\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22314355 1.91629073 1.51082562 1.91629073 1.91629073 1.91629073\n",
      " 1.91629073]\n",
      "{'people': 2, 'wathch': 4, 'anime': 0, 'watch': 3, 'wite': 5, 'comment': 1, 'write': 6}\n",
      "[1.22314355 1.91629073 1.51082562 1.91629073 1.91629073 1.91629073\n",
      " 1.91629073]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.idf_)\n",
    "print(tfidf.vocabulary_)\n",
    "print(tfidf.tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".deeplr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
